\chapter{Multicast in IPv4}

IP multicast was added as an additional addressing model. The first
references can be found in \rfc{966}. This RFC defines multicast traffic
with many responsibilities for routers (called ``multicast agents'' at that time)
and it was soon obsoleted and served only as an inspiration. The latest
specification can be found in \rfc{1112}.

In local networks, multicasts are similar to broadcasts. Every packet is to be
transmitted to every host on the same link, and each host can decide according to
the destination address whether or not the packet should be processed or altogether
dropped. In other words, you need neither a multicast routing capable router
nor any special network hardware to use multicast in one network. Differences
are notable on inter-network level. While broadcasts should be either forwarded
to all links or filtered completely by routers, multicasts should have a more
controlled behavior.

\section{Multicast groups}

The first term we need to understand is the \emph{multicast group}. It is represented by an IP
address allocated from a dedicated region \prefix{224.0.0.0/4}. This region is further
divided into blocks, which have additional semantics. From routing point of
view, only the Local Network Control Block (\prefix{224.0.0.0/24}) is
interesting. Multicasts in this group must never be forwarded and they stay
in the boundary of a~local network. This block is often used by unicast
routing protocols.

Host membership in a group is fully optional. Neither the number of members in
a group nor the number of groups a host belongs to is limited and it can be even
zero. A host does not have to belong to a group to send packets into it.
Multicast packets are distributed in the same ``best effort'' manner as unicast ones -- they can
be delivered to all, some or no hosts, and in any order.

There are three levels of conformance with IP multicast. Level 0 means no
conformance. Level 1 requires hosts to be able to send packets to multicast
groups. This level still requires little code in the networking stack, because
sending a~packet to a multicast group is very similar to sending it as an unicast
packet with a destination address set to the group address. While it doesn't make much
sense to send unicast packets destined outside the local network prefix directly
to the link, it is the expected behavior with multicast. Level 2 means fully
conforming, able to send and receive multicast traffic.

\section{Internet Group Management Protocol}

As already said, membership in a multicast group is optional. By default, there
is only one group that every host listens to --- the \ttt{ALL-HOSTS} group with address
\ip{224.0.0.1}. There must be a way for hosts to express group membership.
A~protocol exists for this purpose and it is called IGMP.

The most recent version of IGMP is 3. It is described in \rfc{3376}. However, all
versions are backwards compatible. Whenever there is a router which only knows
an older version, all the newer ones stop sending any packets and they only receive and observe.

The purpose of IGMP is to exchange information about group membership between
hosts and routers. Note that it is mandatory to implement IGMP in order to participate in
a multicast group, but until a multicast packet crosses the boundary of a single network, it
is delivered as broadcast to all hosts. As such all hosts receive it without
the routers being involved.

Let us start with IGMP version 1 specified in Appendix I of \rfc{1112}. There
are just two types of messages: \emph{membership query} and \emph{membership report}.
Membership query is sent periodically by routers. It announces to hosts that there
is an IGMPv1 capable router. This query is sent to \ttt{ALL-HOSTS} group with TTL~1 and
therefore is limited to the local network. When a host receives a query, it replies with
a membership report in 10 seconds with a random delay. No host should send
reports for the \ttt{ALL-HOSTS} group, membership there is implicit and mandatory.

The report is sent to the group being reported. As noted above, the host does not have
to send reports in order to listen. Filtering multicast traffic is made by other means.
Sending a~report declares there is someone interested in this group on this
particular link. When, during the random delay, the host receives a~report, it
stops his own timer and remains silent. This reduces the amount of control
traffic. When the host decides to leave a group, it does nothing. If it was the
only host in that group, on the next query no one will report and the routers will
stop forwarding.

IGMPv2 \cite{rfc2236} comes with major changes. First, a router can send
a query to a~single specific group. That means it can keep a timer for every group
separately, and asking for reports does not generate unnecessary traffic in
every other group. Second, the maximum delay between a query and the report
(previously fixed to 10 seconds) is now specified in each query and it is
configurable. A network administrator can tune this variable for his needs.
When the value is decreased, hosts will reply faster and routers can faster stop
forwarding. Giving longer delays can improve stability on very slow or
unreliable links.

The most notable change though is a new message type -- \emph{leave group}. When a host
sends a~report, it sets a flag. Other hosts without the flag remain silent. When
the flagged host leaves a group, it sends the leave group message. Other hosts
react to other hosts' leave in a way similar to a query. When a router hears the leave,
it starts a timer. This timer can be stopped by receiving a~report. Expiring this
timer immediately changes this group state to not having any members. This way
less unnecessary traffic is forwarded.

IGMPv3 comes with additional fields and more complex protocol logic. It is
dedicated to source-specific multicast forwarding and includes messages to manage
a set of sources for every link. Routers should then forward only traffic from
these sources onto this link.

For purpose of this thesis, only IGMPv2 was implemented, as PIM-BIDIR is not
a~source-specific routing protocol.

\section{Link layer}

Even though multicast is specified on the network layer, it needs some level of
support from the link layer. Let us explain how multicast traffic integrates with
the most common combination of IP over Ethernet.

The first problem we need to solve is which MAC address to use for multicast
group addresses. When sending an unicast packet, a mechanism called Address
Resolution Protocol (\emph{ARP}, \rfc{826}) is used to determine the MAC
address. It is done simply by broadcasting questions ``Who has this IP
address?'' and collecting answers and caching them.

As the multicast is technically a broadcast on the link layer, it would be possible to
use the broadcast address \mac{FF:FF:FF:FF:FF:FF}.
But that would mean that every multicast packet on the network must be received by all
hosts and examined by their operating systems, because there is no way how to filter
it on the hardware level. For this purpose, every Ethernet address with the
least-significant bit of the first byte set is considered to be
a broadcast address and is to be flooded to all nodes on this network. Network
hardware generally does not make a difference between them, so we can associate
specific meaning to different MAC addresses.

For IPv4 multicast, a region of MAC addresses was allocated. This region starts
at \mac{01:00:5E:00:00:00} and ends with \mac{01:00:5E:7F:FF:FF}. You can see
that this address space is smaller (only 23 bits) than the multicast IP region
(28~bits). To construct the MAC address from the multicast group address, one
puts lower 23 bits of the IP address to the lower bits of the MAC address. This
way, network interfaces can implement a rough filter, that can drop frames the
host knows nothing about. Additional filtering is still needed because of those
missing bits.

A multicast router needs to receive packets for all groups because IGMP reports
are sent there. To enable this behavior, interfaces often have an ``all multicast''
mode, which lets all multicast frames pass through. This mode is also used when
the filter table on the NIC is too small to contain all the filters needed. Or
we can put the NIC into a so-called promiscuous mode, which passes all frames
to the operating system.

\subsection{IGMP snooping}

What was written above is true according to the specifications, but not really
reflecting the real state of the art. Link layer hardware such as switches often does
make a difference and it uses a technique called \emph{IGMP snooping}. This is described
in \rfc{4541}. This RFC is only informational, because a lot of network hardware with
this functionality was produced before this RFC and it does not behave in any
standardized way. Network switches performing IGMP snooping understand IGMP. They
listen to routers communicating with hosts and they filter multicast traffic on
the link layer.

At the first glance, this seems reasonable, because it stops forwarding packets
to network segments without any receivers, thus saving bandwidth. On the other
hand, this high-level functionality is expected from the network layer, and
reimplementing it in the link layer brings many corner cases, which can prevent
local multicast from working at all. Especially when connecting two multicast
routers with a bridge, you must disable IGMP snooping, because it will filter
out all traffic for which the router is not a local host -- most probably
everything you want to route.

For instance, Linux virtual bridges have IGMP snooping turned on by default.
You can check its status and configure it through special files located in
\ttt{/sys/devices/virtual/{\it netdev\/}/bridge/}.

\def\setsockopt{\ttt{set\-sock\-opt} }
\section{Kernel implementation}

The system interface for multicast is pretty complicated. At least, differences
between Unixes are not big. Let us start with code to receive multicast traffic
in an ordinary application. It is not much harder than opening a socket to
receive unicasts:

\lstinputlisting[firstline=8, lastline=18]{examples/socket.c}

\noindent You might have expected that we would \emph{bind} the socket to the
multicast group address. That is not true. A socket can join an arbitrary
number of groups. Instead, we're binding it to a wildcard address and joining
the group issuing a~\setsockopt call.

One thing to note here. When there is a socket opened which joined a group, the host itself joins the group by means of IGMP. And when the host is
joined, every other multicast-enabled socket will get all packets addressed to that
group. So, you still need to filter those at the transport layer (using ports
for example) or by yourself in the application.

When the router daemon wants to receive all the IGMP packets for all groups, it
would have to join every group possible. That is certainly not the way to go.
IGMPv2 suggests using the IP option \emph{Router Alert}. Every IP packet with this option
set should be passed to all sockets that order it by this \setsockopt call:

\lstinputlisting[firstline=8, lastline=11]{examples/igmp_socket.c}

\noindent There are multiple problems with this. Backward compatibility with
IGMPv1 is broken, and standard does not force hosts to set the option. Some (e.g.,
old Cisco) routers do not do it.

Surprisingly, there is only one way how to get all IGMP packets coming on
some interface. That is opening the IGMP control socket.

\subsection{Multicast kernel interface}
\label{mcast-kernel}

When we want to control kernel multicast routing tables, we need to open
a~control socket. That is a raw IP socket with a type \ttt{IPPROTO\_IGMP}.
Then, a~\setsockopt call is needed:

\begin{lstlisting}[language=c]
int fd = socket(AF_INET, SOCK_RAW, IPPROTO_IGMP);

int v = 1;
setsockopt(fd, IPPROTO_IP, MRT_INIT, &v, sizeof(v));
\end{lstlisting}

\noindent Syscalls \ttt{setsockopt} related to the multicast have option names starting
with \ttt{MRT\_}. These constants are defined in \ttt{<linux/mroute.h>}.
Because they are essentially function calls, allow us to say ``call
\ttt{MRT\_INIT}'' with the meaning of calling \setsockopt with the option
name \ttt{MRT\_INIT}.

There can be only one socket on which the call \ttt{MRT\_INIT} succeeds. That socket
is stored in the kernel and it is used for multiple purposes. By issuing further
\setsockopt calls, one can control multicast routing tables. What is not well
documented is that this is the only socket on a host which can receive all IGMP
packets. Because of this limitation, it is not possible to run more than one
multicast routing daemon.

Let us have a look on how to control the multicast routing. As the first thing
we need to add \emph{virtual interfaces} (VIFs). A VIF can be built on top of
a~real network device, an IPIP tunnel, or it can create a special purpose device.
Multicast routing table entries operate only on subsets of VIFs.

There can be only a very limited number of VIFS. This number is currently
controlled by a kernel compile-time constant \ttt{MAXVIFS}, which defaults to 32. It is not easy
to change it, because it breaks the kernel ABI. Every VIF has an index from the
range $0\dots31$. To add a VIF, we must fill \ttt{struct vifctl} and call
\ttt{MRT\_ADD\_VIF}:

\begin{lstlisting}[language=c]
struct vifctl vc = { 0 };
vc.vifc_vifi = 1;
vc.vifc_flags = VIFF_USE_IFINDEX;
vc.vifc_lcl_ifindex = 2;

setsockopt(igmp_sock, IPPROTO_IP, MRT_ADD_VIF, &vc, sizeof(vc));
\end{lstlisting}

\noindent We are creating a VIF representing real network interface with index 2. This VIF will
get assigned the index 1. We can use an interface address to target a real
interface instead of interface index, or specify destination address for the
IPIP tunnel. If we set the \ttt{VIFF\_REGISTER} flag, special device will be created.

The kernel does not provide regular routing tables. The structure used for
forwarding is called Multicast Forwarding Cache (MFC). A MFC entry can be added
by filling a \ttt{struct mfcctl} and calling \ttt{MRT\_ADD\_MFC} or
\ttt{MRT\_ADD\_MFC\_PROXY}. The difference between these two will be
explained later.

\begin{lstlisting}[language=c]
struct mfcctl mc = { 0 };

mc.mfcc_origin = in_source;
mc.mfcc_mcastgrp = in_group;
mc.mfcc_parent = vifi;

for (int i = 0; i < MAXVIFS; i++)
    mc.mfcc_ttls[i] = ttl_threshold[i];

setsockopt(igmp_sock, IPPROTO_IP, MRT_ADD_MFC, &mc, sizeof(mc));
\end{lstlisting}

\noindent The basic meaning of an MFC entry is hidden in the field \ttt{mfcc\_ttls}. It is
an array of \ttt{MAXVIFS} integers, indexed by the VIF index. Whenever a field for the VIF is
either 0 or 255, we call the VIF inactive for this entry, otherwise we call it
active.

The entries are indexed by source and group address. When a packet for a~pair $(S,G)$
arrives on any interface, it is first checked whether it came from the
interface \ttt{mfcc\_parent}. If not, it is dropped immediately. Otherwise
for every active VIF~$i$, the packet's TTL is compared to the threshold in
\ttt{mfcc\_ttls[$i$]}. If the packet's TTL is greater, it is copied to the
VIF~$i$.

In Linux, there are two more types of MFC entries: $(*,G)$ and $(*,*)$. These
are added by a call \ttt{MFC\_ADD\_MFC\_PROXY}, and they have a completely different
meaning. I haven't found any explanation for these, my assumptions are based on
studying the kernel source code. The proxy entries are used to build a shared
tree, possibly statically, common for all groups. First, you have to choose one
uplink interface~$i$, and add a~$(*,*)$ entry with a \ttt{mfcc\_parent} set
to~$i$. Whenever a packet comes to an active interface, and no $(*, G)$ MFC
entry is present yet, it is forwarded to the uplink.

For a simple example, imagine your home router. It probably has three
interfaces: the uplink \ttt{wan}, wired \ttt{lan} and wireless
\ttt{wlan} downlinks.\footnote{Those two downlinks are probably internally
bridged in your router, but not in this example.} A $(*,*)$ entry with
\ttt{wan} and \ttt{lan} as active interfaces would enable you to send
multicast packets from hosts on \ttt{lan}, which would then be forwarded to
\ttt{wan}. Multicast packets sent on \ttt{wlan} would be dropped.

Then, you can specify some~$(*,G)$ entries. Having a~$(*,G)$ entry with parent~$p$,
when a packet comes on an interface~$j$, and there is a~$(*,*)$ entry with
both~$p$ and~$j$ active, the packet is forwarded to all interfaces active in
the~$(*,G)$ entry with the exception of~$j$. Following the previous example,
you would add an~$(*,G)$ entry with all three interfaces active for a group
that you want to be delivered to both of your links. Any multicast packet
received on either \ttt{wan} or \ttt{lan} would be forwarded to the
remaining interfaces.

Note that even when a $(*,G)$ entry is present, the kernel looks for a $(*,*)$
entry to filter the incoming interface. There can be more $(*,*)$ entries with
different uplinks, but it will work only when the active interfaces are
disjoint. There are no checks to prevent you from adding an entry that would
never be found, so it is hard to guess which behavior is intentional and which
is not.

You may wonder whether it is possible to add unicast routes for multicast
addresses. It is, but their meaning is different. These routes are never used
to forward packets. Instead, when you open a socket and do not specify an
outgoing interface for a multicast packet (\ttt{IP\_MULTICAST\_IF}), the interface
will be selected according to these routes. If no matching route exists, the sending
will fail.
